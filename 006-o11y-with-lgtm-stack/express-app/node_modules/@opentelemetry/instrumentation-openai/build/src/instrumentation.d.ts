import type { Attributes, Context, Span } from '@opentelemetry/api';
import { InstrumentationBase, InstrumentationNodeModuleDefinition } from '@opentelemetry/instrumentation';
import type { ChatCompletion, ChatCompletionCreateParams, ChatCompletionChunk } from 'openai/resources/chat/completions';
import type { CreateEmbeddingResponse, EmbeddingCreateParams } from 'openai/resources/embeddings';
import { OpenAIInstrumentationConfig } from './types';
export declare class OpenAIInstrumentation extends InstrumentationBase<OpenAIInstrumentationConfig> {
    private _genaiClientOperationDuration;
    private _genaiClientTokenUsage;
    constructor(config?: OpenAIInstrumentationConfig);
    setConfig(config?: OpenAIInstrumentationConfig): void;
    protected init(): InstrumentationNodeModuleDefinition[];
    _updateMetricInstruments(): void;
    _getPatchedChatCompletionsCreate(): any;
    /**
     * Start a span for this chat-completion API call. This also emits log events
     * as appropriate for the request params.
     */
    _startChatCompletionsSpan(params: ChatCompletionCreateParams, config: OpenAIInstrumentationConfig, baseURL: string | undefined): {
        span: Span;
        ctx: Context;
        commonAttrs: Attributes;
    };
    /**
     * This wraps an instance of a `openai/streaming.Stream.iterator()`, an
     * async iterator. It should yield the chunks unchanged, and gather telemetry
     * data from those chunks, then end the span.
     */
    _onChatCompletionsStreamIterator(streamIter: AsyncIterator<ChatCompletionChunk>, span: Span, startNow: number, config: OpenAIInstrumentationConfig, commonAttrs: Attributes, ctx: Context): AsyncGenerator<any, void, unknown>;
    _onChatCompletionsCreateResult(span: Span, startNow: number, commonAttrs: Attributes, result: ChatCompletion, config: OpenAIInstrumentationConfig, ctx: Context): void;
    _createAPIPromiseRejectionHandler(startNow: number, span: Span, commonAttrs: Attributes): (err: Error) => void;
    _getPatchedEmbeddingsCreate(): any;
    /**
     * Start a span for this chat-completion API call. This also emits log events
     * as appropriate for the request params.
     */
    _startEmbeddingsSpan(params: EmbeddingCreateParams, baseURL: string | undefined): {
        span: Span;
        ctx: Context;
        commonAttrs: Attributes;
    };
    _onEmbeddingsCreateResult(span: Span, startNow: number, commonAttrs: Attributes, result: CreateEmbeddingResponse): void;
}
//# sourceMappingURL=instrumentation.d.ts.map